{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9762121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tobacco smoking': 0.2780719051126377,\n",
       " 'chronic cough': 0.034851554559677034,\n",
       " 'radon exposure': 0.2364527976600279}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = 'predicting lung cancer decision tree - there are five features.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data.head()\n",
    "\n",
    "y = data['Lung Cancer']\n",
    "\n",
    "# Define the calculate_entropy function \n",
    "def calculate_entropy(y):\n",
    "    value_counts = y.value_counts()\n",
    "    probabilities = value_counts / len(y)\n",
    "    # Calculate entropy using the formula\n",
    "    entropy = -sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "# Define the calculate_information_gain function\n",
    "def calculate_information_gain(X, y, attribute):\n",
    "    original_entropy = calculate_entropy(y)\n",
    "    \n",
    "    # Values of the attribute\n",
    "    values = X[attribute].unique()\n",
    "    \n",
    "    # Calculate the weighted entropy after the split\n",
    "    weighted_entropy_sum = 0\n",
    "    for value in values:\n",
    "        subset = y[X[attribute] == value]\n",
    "        subset_entropy = calculate_entropy(subset)\n",
    "        weighted_entropy_sum += (len(subset) / len(y)) * subset_entropy\n",
    "    \n",
    "    information_gain = original_entropy - weighted_entropy_sum\n",
    "    return information_gain\n",
    "\n",
    "# Extract the 'Lung Cancer' column as the target variable\n",
    "y = data['Lung Cancer']\n",
    "\n",
    "# Calculate information gain for specified attributes\n",
    "information_gains = {attribute: calculate_information_gain(data, y, attribute) \n",
    "                     for attribute in ['tobacco smoking', 'chronic cough', 'radon exposure']}\n",
    "\n",
    "information_gains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6acb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4253642047367425"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Calculate areas for each class\n",
    "area_A = (0.8 * 0.4) + (0.3 * 0.3)\n",
    "area_B = (0.7 * 0.6) + (0.2 * 0.2)\n",
    "area_C = (0.3 * 0.3) + (0.2 * 0.2)\n",
    "\n",
    "# Calculate probabilities for each class\n",
    "p_A = area_A\n",
    "p_B = area_B\n",
    "p_C = area_C\n",
    "\n",
    "# Total area is 1 since it's a unit square\n",
    "total_area = 1\n",
    "\n",
    "# Normalize the probabilities \n",
    "p_A /= total_area\n",
    "p_B /= total_area\n",
    "p_C /= total_area\n",
    "\n",
    "# Calculate the entropy for the overall data\n",
    "entropy = - (p_A * math.log2(p_A) + p_B * math.log2(p_B) + p_C * math.log2(p_C))\n",
    "\n",
    "entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daf8c10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46438561897747255, 1.3778874048877483, 1.3219405620899831)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the function to calculate entropy for a given probability distribution\n",
    "def calculate_entropy(probabilities):\n",
    "    return -sum(p * math.log2(p) for p in probabilities if p > 0)\n",
    "\n",
    "# Split at x ≤ 0.2 (all figures have height 1)\n",
    "# This split will cut through classes B and C, which have parts in the region (x <= 0.2)\n",
    "area_B_x_le_02 = 0.2 * 1  # Rectangle of class B in the split region\n",
    "area_C_x_le_02 = 0.2 * 0.2  # Square of class C in the split region\n",
    "total_area_x_le_02 = 0.2  # Total area of the split region\n",
    "\n",
    "# Calculate probabilities for each class in the split at x ≤ 0.2\n",
    "p_B_x_le_02 = area_B_x_le_02 / total_area_x_le_02\n",
    "p_C_x_le_02 = area_C_x_le_02 / total_area_x_le_02\n",
    "\n",
    "# Entropy for the split at x ≤ 0.2\n",
    "entropy_x_le_02 = calculate_entropy([p_B_x_le_02, p_C_x_le_02])\n",
    "\n",
    "# Split at x ≤ 0.7\n",
    "# This split will cut through class A\n",
    "area_A_x_le_07 = 0.7 * 0.4  # Rectangle of class A in the split region\n",
    "total_area_x_le_07 = 0.7  # Total area of the split region\n",
    "\n",
    "# Calculate probabilities for each class in the split at x ≤ 0.7\n",
    "p_A_x_le_07 = area_A_x_le_07 / total_area_x_le_07\n",
    "p_B_x_le_07 = area_B / total_area_x_le_07\n",
    "p_C_x_le_07 = area_C / total_area_x_le_07\n",
    "\n",
    "# Entropy for the split at x ≤ 0.7\n",
    "entropy_x_le_07 = calculate_entropy([p_A_x_le_07, p_B_x_le_07, p_C_x_le_07])\n",
    "\n",
    "# Split at y ≤ 0.6\n",
    "# This split will cut through classes A and B\n",
    "area_B_y_le_06 = 0.7 * 0.6  # Rectangle of class B in the split region\n",
    "area_A_y_le_06 = 0.8 * (1 - 0.6)  # Rectangle of class A in the split region\n",
    "total_area_y_le_06 = 1 * 0.6  # Total area of the split region\n",
    "\n",
    "# Calculate probabilities for each class in the split at y ≤ 0.6\n",
    "p_A_y_le_06 = area_A_y_le_06 / total_area_y_le_06\n",
    "p_B_y_le_06 = area_B_y_le_06 / total_area_y_le_06\n",
    "p_C_y_le_06 = area_C / total_area_y_le_06\n",
    "\n",
    "# Entropy for the split at y ≤ 0.6\n",
    "entropy_y_le_06 = calculate_entropy([p_A_y_le_06, p_B_y_le_06, p_C_y_le_06])\n",
    "\n",
    "entropy_x_le_02, entropy_x_le_07, entropy_y_le_06\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c1cd2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5637042123338319, 0.3022116499288352, 0.3851023887264644)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The entropy of the original set was calculated previously\n",
    "entropy_original = entropy\n",
    "\n",
    "# Proportion of samples in each subset for the split at x ≤ 0.2\n",
    "prop_x_le_02 = 0.2\n",
    "prop_x_gt_02 = 1 - prop_x_le_02\n",
    "\n",
    "# Weighted average entropy for the split at x ≤ 0.2\n",
    "# Note: The entropy for the region x > 0.2 can be considered as the remaining entropy after subtracting the entropy for x ≤ 0.2\n",
    "weighted_entropy_x_le_02 = prop_x_le_02 * entropy_x_le_02 + prop_x_gt_02 * (entropy_original - entropy_x_le_02)\n",
    "\n",
    "# Information Gain for the split at x ≤ 0.2\n",
    "info_gain_x_le_02 = entropy_original - weighted_entropy_x_le_02\n",
    "\n",
    "# Proportion of samples in each subset for the split at x ≤ 0.7\n",
    "prop_x_le_07 = 0.7\n",
    "prop_x_gt_07 = 1 - prop_x_le_07\n",
    "\n",
    "# Since the split at x ≤ 0.7 involves the whole class B and C, the entropy for x > 0.7 is just the entropy for the remaining part of class A\n",
    "area_A_x_gt_07 = 0.3 * 0.4\n",
    "p_A_x_gt_07 = area_A_x_gt_07 / (1 - prop_x_le_07)\n",
    "entropy_x_gt_07 = calculate_entropy([p_A_x_gt_07])\n",
    "\n",
    "# Weighted average entropy for the split at x ≤ 0.7\n",
    "weighted_entropy_x_le_07 = prop_x_le_07 * entropy_x_le_07 + prop_x_gt_07 * entropy_x_gt_07\n",
    "\n",
    "# Information Gain for the split at x ≤ 0.7\n",
    "info_gain_x_le_07 = entropy_original - weighted_entropy_x_le_07\n",
    "\n",
    "# Proportion of samples in each subset for the split at y ≤ 0.6\n",
    "prop_y_le_06 = 0.6\n",
    "prop_y_gt_06 = 1 - prop_y_le_06\n",
    "\n",
    "# Since the split at y ≤ 0.6 involves the whole class C, the entropy for y > 0.6 is just the entropy for the remaining parts of classes A and B\n",
    "area_A_y_gt_06 = 0.8 * 0.4\n",
    "area_B_y_gt_06 = 0.7 * (1 - 0.6)\n",
    "p_A_y_gt_06 = area_A_y_gt_06 / (1 - prop_y_le_06)\n",
    "p_B_y_gt_06 = area_B_y_gt_06 / (1 - prop_y_le_06)\n",
    "entropy_y_gt_06 = calculate_entropy([p_A_y_gt_06, p_B_y_gt_06])\n",
    "\n",
    "# Weighted average entropy for the split at y ≤ 0.6\n",
    "weighted_entropy_y_le_06 = prop_y_le_06 * entropy_y_le_06 + prop_y_gt_06 * entropy_y_gt_06\n",
    "\n",
    "# Information Gain for the split at y ≤ 0.6\n",
    "info_gain_y_le_06 = entropy_original - weighted_entropy_y_le_06\n",
    "\n",
    "info_gain_x_le_02, info_gain_x_le_07, info_gain_y_le_06\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "807a2a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV data into a DataFrame\n",
    "csv_path = 'question3 gini table - Sheet1.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Display the first few rows of the dataframe to ensure it's loaded correctly\n",
    "data.head()\n",
    "\n",
    "# Calculate the Gini index for the 'class' column\n",
    "\n",
    "# Count the occurrences of each class\n",
    "class_counts = data['class'].value_counts()\n",
    "\n",
    "# Calculate the proportion of each class\n",
    "proportions = class_counts / class_counts.sum()\n",
    "\n",
    "# Calculate the Gini index\n",
    "gini_index = 1 - sum(proportions**2)\n",
    "gini_index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4034e2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48,\n",
       " Gender\n",
       " f    0.48\n",
       " m    0.48\n",
       " dtype: float64,\n",
       " Gender\n",
       " f    0.5\n",
       " m    0.5\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gender_class_counts = data.groupby(['Gender', 'class']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate the proportion of classes within each gender group\n",
    "gender_proportions = gender_class_counts.divide(gender_class_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# Calculate the Gini index for each gender group\n",
    "gender_gini = 1 - (gender_proportions**2).sum(axis=1)\n",
    "\n",
    "# Calculate the weighted average Gini index for the 'Gender' attribute\n",
    "weights = gender_class_counts.sum(axis=1) / data.shape[0]\n",
    "gini_index_gender = (gender_gini * weights).sum()\n",
    "gini_index_gender, gender_gini, weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "730fb1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16250000000000003,\n",
       " car type\n",
       " Family    0.37500\n",
       " Luxury    0.21875\n",
       " Sports    0.00000\n",
       " dtype: float64,\n",
       " car type\n",
       " Family    0.2\n",
       " Luxury    0.4\n",
       " Sports    0.4\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Gini index for the 'Car Type' attribute with a multiway split\n",
    "\n",
    "# First, group the data by 'Car Type' and then by 'Class' to count occurrences\n",
    "car_type_class_counts = data.groupby(['car type', 'class']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate the proportion of classes within each car type group\n",
    "car_type_proportions = car_type_class_counts.divide(car_type_class_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# Calculate the Gini index for each car type group\n",
    "car_type_gini = 1 - (car_type_proportions**2).sum(axis=1)\n",
    "\n",
    "# Calculate the weighted average Gini index for the 'Car Type' attribute\n",
    "weights_car_type = car_type_class_counts.sum(axis=1) / data.shape[0]\n",
    "gini_index_car_type = (car_type_gini * weights_car_type).sum()\n",
    "gini_index_car_type, car_type_gini, weights_car_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f9083a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49142857142857144,\n",
       " shirt size\n",
       " extra large    0.500000\n",
       " large          0.500000\n",
       " medium         0.489796\n",
       " small          0.480000\n",
       " dtype: float64,\n",
       " shirt size\n",
       " extra large    0.20\n",
       " large          0.20\n",
       " medium         0.35\n",
       " small          0.25\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Gini index for the 'Shirt Size' attribute with a multiway split\n",
    "\n",
    "# First, group the data by 'Shirt Size' and then by 'Class' to count occurrences\n",
    "shirt_size_class_counts = data.groupby(['shirt size', 'class']).size().unstack(fill_value=0)\n",
    "\n",
    "# Calculate the proportion of classes within each shirt size group\n",
    "shirt_size_proportions = shirt_size_class_counts.divide(shirt_size_class_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# Calculate the Gini index for each shirt size group\n",
    "shirt_size_gini = 1 - (shirt_size_proportions**2).sum(axis=1)\n",
    "\n",
    "# Calculate the weighted average Gini index for the 'Shirt Size' attribute\n",
    "weights_shirt_size = shirt_size_class_counts.sum(axis=1) / data.shape[0]\n",
    "gini_index_shirt_size = (shirt_size_gini * weights_shirt_size).sum()\n",
    "gini_index_shirt_size, shirt_size_gini, weights_shirt_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f38e7874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09000000000000001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Width and height of the rectangle where misclassifications occur\n",
    "width_misclass = 0.5 - 0.2\n",
    "height_misclass = 1.0 - 0.7\n",
    "\n",
    "# Calculate the area of misclassification\n",
    "area_misclass = width_misclass * height_misclass\n",
    "\n",
    "# Calculate the expected error rate (total area is 1 for a unit square)\n",
    "expected_error_rate = area_misclass / 1\n",
    "expected_error_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18bb37d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Initial probabilities for positive and negative classes\n",
    "p_positive = 10 / 20\n",
    "p_negative = 10 / 20\n",
    "\n",
    "# Calculate initial entropy of S\n",
    "entropy_s = -(p_positive * math.log2(p_positive) + p_negative * math.log2(p_negative))\n",
    "\n",
    "# Information gain for ID (since the entropy of each split is 0)\n",
    "information_gain_id = entropy_s - 0\n",
    "\n",
    "entropy_s, information_gain_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd09b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4689955935892812,\n",
       " 0.4689955935892812,\n",
       " 0.4689955935892812,\n",
       " 0.5310044064107188)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportions for left-handed and right-handed subsets\n",
    "p_left_positive = 9 / 10\n",
    "p_left_negative = 1 / 10\n",
    "p_right_positive = 1 / 10\n",
    "p_right_negative = 9 / 10\n",
    "\n",
    "# Calculate entropies for left-handed and right-handed subsets\n",
    "entropy_left = -(p_left_positive * math.log2(p_left_positive) + p_left_negative * math.log2(p_left_negative))\n",
    "entropy_right = -(p_right_positive * math.log2(p_right_positive) + p_right_negative * math.log2(p_right_negative))\n",
    "\n",
    "# Calculate the weighted sum of these entropies\n",
    "weighted_entropy = (10 / 20) * entropy_left + (10 / 20) * entropy_right\n",
    "\n",
    "# Information gain for Handedness\n",
    "information_gain_handedness = entropy_s - weighted_entropy\n",
    "\n",
    "entropy_left, entropy_right, weighted_entropy, information_gain_handedness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "582d4207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.321928094887363, 0.23137821315975915)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of partitions (each instance forms its own partition)\n",
    "k = 20\n",
    "\n",
    "# Calculate Split Information for ID\n",
    "split_information_id = -sum([(1/k) * math.log2(1/k) for _ in range(k)])\n",
    "\n",
    "# Calculate Gain Ratio for ID\n",
    "gain_ratio_id = information_gain_id / split_information_id\n",
    "\n",
    "split_information_id, gain_ratio_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f88c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
